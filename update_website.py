#!/usr/bin/env python3
"""
ç½‘ç«™å†…å®¹æ›´æ–°å·¥å…· - å°†æœ€æ–°çˆ¬è™«æ•°æ®æ›´æ–°åˆ°ä¸»ç½‘ç«™
"""

import os
import json
import re
from datetime import datetime
import shutil
import html

class WebsiteUpdater:
    def __init__(self):
        self.main_html_path = "index.html"
        self.data_dir = "crawler/data"
        self.backup_dir = "backups"
        
    def get_latest_data_files(self):
        """è·å–æœ€æ–°çš„æ•°æ®æ–‡ä»¶"""
        if not os.path.exists(self.data_dir):
            print("âŒ æ•°æ®ç›®å½•ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œçˆ¬è™«")
            return None, None
            
        # è·å–æ‰€æœ‰JSONå’ŒHTMLæ–‡ä»¶
        json_files = [f for f in os.listdir(self.data_dir) if f.endswith('.json')]
        html_files = [f for f in os.listdir(self.data_dir) if f.endswith('.html')]
        
        if not json_files or not html_files:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°æ•°æ®æ–‡ä»¶ï¼Œè¯·å…ˆè¿è¡Œçˆ¬è™«")
            return None, None
            
        # è·å–æœ€æ–°æ–‡ä»¶ï¼ˆæŒ‰ä¿®æ”¹æ—¶é—´ï¼‰
        latest_json = max(json_files, key=lambda f: os.path.getmtime(os.path.join(self.data_dir, f)))
        latest_html = max(html_files, key=lambda f: os.path.getmtime(os.path.join(self.data_dir, f)))
        
        json_path = os.path.join(self.data_dir, latest_json)
        html_path = os.path.join(self.data_dir, latest_html)
        
        print(f"ğŸ“„ æœ€æ–°JSONæ–‡ä»¶: {latest_json}")
        print(f"ğŸ“„ æœ€æ–°HTMLæ–‡ä»¶: {latest_html}")
        
        return json_path, html_path

    def load_deals_data(self, json_path):
        """åŠ è½½ä¼˜æƒ æ•°æ®"""
        try:
            with open(json_path, 'r', encoding='utf-8') as f:
                deals = json.load(f)
            print(f"âœ… æˆåŠŸåŠ è½½ {len(deals)} ä¸ªä¼˜æƒ ä¿¡æ¯")
            return deals
        except Exception as e:
            print(f"âŒ åŠ è½½æ•°æ®å¤±è´¥: {e}")
            return []

    def backup_website(self):
        """å¤‡ä»½å½“å‰ç½‘ç«™"""
        if not os.path.exists(self.main_html_path):
            print("âŒ ä¸»ç½‘ç«™æ–‡ä»¶ä¸å­˜åœ¨")
            return False
            
        # åˆ›å»ºå¤‡ä»½ç›®å½•
        os.makedirs(self.backup_dir, exist_ok=True)
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        backup_path = os.path.join(self.backup_dir, f"index_backup_{timestamp}.html")
        
        shutil.copy2(self.main_html_path, backup_path)
        print(f"ğŸ’¾ ç½‘ç«™å·²å¤‡ä»½åˆ°: {backup_path}")
        return True

    def generate_deals_html(self, deals):
        """ç”Ÿæˆä¼˜æƒ ä¿¡æ¯çš„HTML"""
        if not deals:
            return ""
            
        update_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        section_lines = [
            "    <section id=\"deals\" class=\"daily-deals\">",
            "        <div class=\"container\">",
            "            <div class=\"daily-deals-header\">",
            f"                <h2>ğŸ ä»Šæ—¥è‹±å›½ä¼˜æƒ ç²¾é€‰</h2>",
            f"                <p class=\"update-time\">ğŸ•’ æœ€æ–°æ›´æ–°ï¼š{update_time} ï½œ å·²ç­›é€‰ {len(deals)} æ¡çœŸå®ä¼˜æƒ </p>",
            "            </div>",
            "            <div class=\"deals-container\">"
        ]

        for deal in deals:
            title = deal.get('title_zh') or deal.get('title') or 'ä»Šæ—¥ä¼˜æƒ '
            summary = deal.get('summary_zh') or deal.get('description_zh') or deal.get('description') or ''
            usage = deal.get('usage') or 'ä½¿ç”¨æ–¹æ³•ï¼šç‚¹å‡»ä¸‹æ–¹â€œå‰å¾€ä¼˜æƒ â€ï¼ŒæŒ‰ç…§é¡µé¢æç¤ºå®Œæˆæ“ä½œå³å¯é¢†å–å¥–åŠ±ã€‚'
            url = deal.get('url', '#')
            merchant = deal.get('merchant', 'æœªçŸ¥å•†å®¶')
            date = deal.get('date', '')
            image = deal.get('image')

            summary = summary[:120] + 'â€¦' if len(summary) > 120 else summary

            title_html = html.escape(title)
            summary_html = html.escape(summary)
            usage_html = html.escape(usage)
            merchant_html = html.escape(merchant)
            date_html = html.escape(date)
            url_html = html.escape(url)

            section_lines.append("                <article class=\"deal-card\">")

            if image:
                section_lines.append(f"                    <img src=\"{html.escape(image)}\" alt=\"{title_html}\" loading=\"lazy\">")

            section_lines.extend([
                f"                    <h3>{title_html}</h3>",
                f"                    <p class=\"deal-summary\">{summary_html}</p>",
                f"                    <div class=\"deal-usage\">{usage_html}</div>",
                "                    <div class=\"deal-meta\">",
                f"                        <span>ğŸ“… {date_html}</span>",
                f"                        <span>ğŸŒ {merchant_html}</span>",
                "                    </div>",
                f"                    <a href=\"{url_html}\" target=\"_blank\" rel=\"noopener\" class=\"deal-link\">å‰å¾€ä¼˜æƒ </a>",
                "                </article>"
            ])

        section_lines.extend([
            "            </div>",
            "        </div>",
            "    </section>"
        ])

        return "\n".join(section_lines)

    def update_website(self, deals_html):
        """æ›´æ–°ç½‘ç«™å†…å®¹"""
        if not os.path.exists(self.main_html_path):
            print("âŒ ä¸»ç½‘ç«™HTMLæ–‡ä»¶ä¸å­˜åœ¨")
            return False
            
        # è¯»å–å½“å‰ç½‘ç«™å†…å®¹
        with open(self.main_html_path, 'r', encoding='utf-8') as f:
            content = f.read()
            
        # ç§»é™¤æ—§çš„çˆ¬è™«å†…å®¹
        content = re.sub(
            r'<section[^>]*class="[^"]*daily-deals[^"]*"[^>]*>.*?</section>',
            '',
            content,
            flags=re.DOTALL
        )
        
        # æŸ¥æ‰¾æ’å…¥ä½ç½®
        insert_marker = '<section id="benefits" class="benefits">'
        if insert_marker not in content:
            print("âŒ æœªæ‰¾åˆ°æ’å…¥ä½ç½®æ ‡è®°")
            return False
            
        # æ’å…¥æ–°å†…å®¹
        new_content = content.replace(
            insert_marker,
            deals_html + '\n\n    ' + insert_marker
        )
        
        # å†™å…¥æ›´æ–°åçš„å†…å®¹
        with open(self.main_html_path, 'w', encoding='utf-8') as f:
            f.write(new_content)
            
        return True

    def update_from_latest_data(self):
        """ä»æœ€æ–°æ•°æ®æ›´æ–°ç½‘ç«™"""
        print("ğŸ”„ å¼€å§‹æ›´æ–°ç½‘ç«™å†…å®¹...")
        
        # è·å–æœ€æ–°æ•°æ®æ–‡ä»¶
        json_path, html_path = self.get_latest_data_files()
        if not json_path:
            return False
            
        # åŠ è½½æ•°æ®
        deals = self.load_deals_data(json_path)
        if not deals:
            return False
            
        # å¤‡ä»½ç½‘ç«™
        if not self.backup_website():
            return False
            
        # ç”ŸæˆHTML
        deals_html = self.generate_deals_html(deals)
        
        # æ›´æ–°ç½‘ç«™
        if self.update_website(deals_html):
            print("âœ… ç½‘ç«™æ›´æ–°æˆåŠŸï¼")
            print(f"ğŸ“Š å·²æ·»åŠ  {len(deals)} ä¸ªæœ€æ–°ä¼˜æƒ ")
            print("ğŸŒ æ‚¨å¯ä»¥æŸ¥çœ‹æ›´æ–°åçš„ç½‘ç«™æ•ˆæœ")
            return True
        else:
            print("âŒ ç½‘ç«™æ›´æ–°å¤±è´¥")
            return False

def main():
    print("ğŸ”„ ç½‘ç«™å†…å®¹æ›´æ–°å·¥å…·")
    print("=" * 40)
    
    updater = WebsiteUpdater()
    
    if updater.update_from_latest_data():
        print("\nğŸ‰ æ›´æ–°å®Œæˆï¼")
        print("ğŸ’¡ å»ºè®®æ“ä½œ:")
        print("1. åœ¨æµè§ˆå™¨ä¸­æŸ¥çœ‹ç½‘ç«™æ•ˆæœ")
        print("2. å¦‚æœæ»¡æ„ï¼Œå¯ä»¥æ¨é€åˆ°GitHub: git add . && git commit -m 'Update: Latest deals' && git push")
    else:
        print("\nâŒ æ›´æ–°å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")

if __name__ == "__main__":
    main()
