#!/usr/bin/env python3
"""
ç½‘ç«™å†…å®¹æ›´æ–°å·¥å…· - å°†æœ€æ–°çˆ¬è™«æ•°æ®æ›´æ–°åˆ°ä¸»ç½‘ç«™
"""

import os
import json
import re
from datetime import datetime
import shutil

class WebsiteUpdater:
    def __init__(self):
        self.main_html_path = "index.html"
        self.data_dir = "crawler/data"
        self.backup_dir = "backups"
        self.sample_data_dir = "crawler/sample_data"
        self.sample_json = os.path.join(self.sample_data_dir, "enhanced_deals_sample.json")
        self.required_real_deals = 6

    def get_latest_data_files(self):
        """è·å–æœ€æ–°çš„æ•°æ®æ–‡ä»¶"""
        if not os.path.exists(self.data_dir):
            print("âš ï¸ æ•°æ®ç›®å½•ä¸å­˜åœ¨ï¼Œå°è¯•ä½¿ç”¨ç¤ºä¾‹æ•°æ®")
            return self.get_sample_data_files()

        # è·å–æ‰€æœ‰JSONå’ŒHTMLæ–‡ä»¶
        json_files = [f for f in os.listdir(self.data_dir) if f.endswith('.json')]
        html_files = [f for f in os.listdir(self.data_dir) if f.endswith('.html')]

        if not json_files:
            print("âš ï¸ æ²¡æœ‰æ‰¾åˆ°JSONæ•°æ®æ–‡ä»¶ï¼Œå°è¯•ä½¿ç”¨ç¤ºä¾‹æ•°æ®")
            return self.get_sample_data_files()

        # è·å–æœ€æ–°JSONæ–‡ä»¶ï¼ˆæŒ‰ä¿®æ”¹æ—¶é—´ï¼‰
        latest_json = max(json_files, key=lambda f: os.path.getmtime(os.path.join(self.data_dir, f)))
        json_path = os.path.join(self.data_dir, latest_json)

        latest_html = None
        if html_files:
            latest_html = max(html_files, key=lambda f: os.path.getmtime(os.path.join(self.data_dir, f)))
            html_path = os.path.join(self.data_dir, latest_html)
        else:
            html_path = None

        print(f"ğŸ“„ æœ€æ–°JSONæ–‡ä»¶: {latest_json}")
        if latest_html:
            print(f"ğŸ“„ æœ€æ–°HTMLæ–‡ä»¶: {latest_html}")

        return json_path, html_path

    def get_sample_data_files(self):
        """è·å–ç¤ºä¾‹æ•°æ®æ–‡ä»¶"""
        if os.path.exists(self.sample_json):
            print("âš ï¸ ä½¿ç”¨ç¤ºä¾‹ä¼˜æƒ æ•°æ®è¿›è¡Œæ›´æ–°")
            return self.sample_json, None

        print("âŒ æœªæ‰¾åˆ°ç¤ºä¾‹æ•°æ®æ–‡ä»¶ï¼Œè¯·å…ˆè¿è¡Œçˆ¬è™«ç”Ÿæˆæ•°æ®")
        return None, None

    def load_deals_data(self, json_path):
        """åŠ è½½ä¼˜æƒ æ•°æ®"""
        try:
            with open(json_path, 'r', encoding='utf-8') as f:
                deals = json.load(f)
            print(f"âœ… æˆåŠŸåŠ è½½ {len(deals)} ä¸ªä¼˜æƒ ä¿¡æ¯")
            return deals
        except Exception as e:
            print(f"âŒ åŠ è½½æ•°æ®å¤±è´¥: {e}")
            return []

    def is_real_deal_link(self, url):
        """åˆ¤æ–­æ˜¯å¦ä¸ºçœŸå®å¯è®¿é—®çš„ä¼˜æƒ é“¾æ¥"""
        if not url or not isinstance(url, str):
            return False

        url = url.strip()
        if not url.lower().startswith("http"):
            return False

        blocked_domains = [
            "latestfreestuff.co.uk",
            "facebook.com",
            "twitter.com",
            "instagram.com",
            "youtube.com"
        ]

        return all(domain not in url for domain in blocked_domains)

    def prepare_real_deals(self, deals):
        """ç­›é€‰çœŸå®ä¼˜æƒ å¹¶é™åˆ¶ä¸ºå›ºå®šæ•°é‡"""
        real_deals = []

        for deal in deals or []:
            if not isinstance(deal, dict):
                continue

            url = deal.get('url') or deal.get('claim_url') or deal.get('source_url')
            if not self.is_real_deal_link(url):
                continue

            normalized = deal.copy()
            normalized['url'] = url.strip()
            real_deals.append(normalized)

        meets_requirement = len(real_deals) >= self.required_real_deals
        return real_deals[:self.required_real_deals], meets_requirement

    def backup_website(self):
        """å¤‡ä»½å½“å‰ç½‘ç«™"""
        if not os.path.exists(self.main_html_path):
            print("âŒ ä¸»ç½‘ç«™æ–‡ä»¶ä¸å­˜åœ¨")
            return False
            
        # åˆ›å»ºå¤‡ä»½ç›®å½•
        os.makedirs(self.backup_dir, exist_ok=True)
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        backup_path = os.path.join(self.backup_dir, f"index_backup_{timestamp}.html")
        
        shutil.copy2(self.main_html_path, backup_path)
        print(f"ğŸ’¾ ç½‘ç«™å·²å¤‡ä»½åˆ°: {backup_path}")
        return True

    def generate_deals_html(self, deals, used_sample=False):
        """ç”Ÿæˆä¼˜æƒ ä¿¡æ¯çš„HTMLï¼Œå¹¶è¿”å›å±•ç¤ºæ•°é‡ä¸æ˜¯å¦æ»¡è¶³è¦æ±‚"""
        display_deals, meets_requirement = self.prepare_real_deals(deals)

        if not display_deals:
            return "", 0, meets_requirement

        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        header = f"ğŸ ä»Šæ—¥è‹±å›½ä¼˜æƒ ç²¾é€‰ - {len(display_deals)} ä¸ªçœŸå®å•†å®¶ä¼˜æƒ "
        if used_sample:
            header += "ï¼ˆç¤ºä¾‹æ•°æ®ï¼‰"

        update_line = f"ğŸ•’ æœ€æ–°æ›´æ–°: {timestamp}"
        if used_sample:
            update_line += " | âš ï¸ æš‚æ— å®æ—¶æ•°æ®ï¼Œå±•ç¤ºç¤ºä¾‹ä¼˜æƒ "
        else:
            update_line += " | âœ… æå–çœŸå®å•†å®¶é“¾æ¥"

        html = f"""
    <section id="deals" class="daily-deals">
        <div class="container">
            <div class="daily-deals-section">
                <h2>{header}</h2>
                <p class="update-time">{update_line}</p>
                <div class="deals-container">
"""
        
        for deal in display_deals:
            title_zh = deal.get('title_zh', deal.get('title', ''))
            desc_zh = deal.get('description_zh', deal.get('description', ''))

            # é™åˆ¶æè¿°é•¿åº¦
            if len(desc_zh) > 100:
                desc_zh = desc_zh[:100] + "..."
                
            html += f"""
                    <div class="deal-item">
                        <h3>{title_zh}</h3>
                        <p>{desc_zh}</p>
                        <div class="deal-meta">
                            <span class="date">ğŸ“… {deal.get('date', '')}</span>
                            <a href="{deal.get('url', '#')}" target="_blank" class="deal-link">æŸ¥çœ‹è¯¦æƒ…</a>
                        </div>
                    </div>
"""
        
        html += """
                </div>
            </div>
        </div>
    </section>
"""
        return html, len(display_deals), meets_requirement

    def update_website(self, deals_html):
        """æ›´æ–°ç½‘ç«™å†…å®¹"""
        if not os.path.exists(self.main_html_path):
            print("âŒ ä¸»ç½‘ç«™HTMLæ–‡ä»¶ä¸å­˜åœ¨")
            return False
            
        # è¯»å–å½“å‰ç½‘ç«™å†…å®¹
        with open(self.main_html_path, 'r', encoding='utf-8') as f:
            content = f.read()
            
        # ç§»é™¤æ—§çš„çˆ¬è™«å†…å®¹
        content = re.sub(
            r'<section[^>]*class="daily-deals"[^>]*>.*?</section>',
            '',
            content,
            flags=re.DOTALL
        )

        # æŸ¥æ‰¾æ’å…¥ä½ç½®
        match = re.search(r'<section[^>]*id="benefits"[^>]*>', content)
        if not match:
            print("âŒ æœªæ‰¾åˆ°æ’å…¥ä½ç½®æ ‡è®°")
            return False

        insert_pos = match.start()

        # æ’å…¥æ–°å†…å®¹
        new_content = content[:insert_pos] + deals_html + "\n\n" + content[insert_pos:]
        
        # å†™å…¥æ›´æ–°åçš„å†…å®¹
        with open(self.main_html_path, 'w', encoding='utf-8') as f:
            f.write(new_content)
            
        return True

    def update_from_latest_data(self):
        """ä»æœ€æ–°æ•°æ®æ›´æ–°ç½‘ç«™"""
        print("ğŸ”„ å¼€å§‹æ›´æ–°ç½‘ç«™å†…å®¹...")
        
        # è·å–æœ€æ–°æ•°æ®æ–‡ä»¶
        json_path, html_path = self.get_latest_data_files()
        if not json_path:
            return False

        used_sample = json_path == self.sample_json

        # åŠ è½½æ•°æ®
        deals = self.load_deals_data(json_path)
        if not deals:
            return False
            
        # å¤‡ä»½ç½‘ç«™
        if not self.backup_website():
            return False
            
        # ç”ŸæˆHTML
        deals_html, display_count, meets_requirement = self.generate_deals_html(deals, used_sample=used_sample)

        if not deals_html:
            print("âŒ æœªæ‰¾åˆ°å¯å±•ç¤ºçš„çœŸå®ä¼˜æƒ é“¾æ¥")
            return False

        if not meets_requirement and not used_sample:
            print(f"âš ï¸ å®æ—¶æ•°æ®ä¸è¶³ {self.required_real_deals} æ¡çœŸå®ä¼˜æƒ ï¼Œå·²ä»…å±•ç¤º {display_count} æ¡")

        # æ›´æ–°ç½‘ç«™
        if self.update_website(deals_html):
            print("âœ… ç½‘ç«™æ›´æ–°æˆåŠŸï¼")
            print(f"ğŸ“Š å·²å±•ç¤º {display_count} ä¸ªçœŸå®ä¼˜æƒ ")
            print("ğŸŒ æ‚¨å¯ä»¥æŸ¥çœ‹æ›´æ–°åçš„ç½‘ç«™æ•ˆæœ")
            return True
        else:
            print("âŒ ç½‘ç«™æ›´æ–°å¤±è´¥")
            return False

def main():
    print("ğŸ”„ ç½‘ç«™å†…å®¹æ›´æ–°å·¥å…·")
    print("=" * 40)
    
    updater = WebsiteUpdater()
    
    if updater.update_from_latest_data():
        print("\nğŸ‰ æ›´æ–°å®Œæˆï¼")
        print("ğŸ’¡ å»ºè®®æ“ä½œ:")
        print("1. åœ¨æµè§ˆå™¨ä¸­æŸ¥çœ‹ç½‘ç«™æ•ˆæœ")
        print("2. å¦‚æœæ»¡æ„ï¼Œå¯ä»¥æ¨é€åˆ°GitHub: git add . && git commit -m 'Update: Latest deals' && git push")
    else:
        print("\nâŒ æ›´æ–°å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")

if __name__ == "__main__":
    main()
