import requests
import json
import re
import time
from datetime import datetime
from html.parser import HTMLParser
import logging
import os

class SimpleTranslator:
    """ç®€å•çš„ç¿»è¯‘æœåŠ¡ï¼ˆå¯æ›¿æ¢ä¸ºå…¶ä»–ç¿»è¯‘APIï¼‰"""
    
    def __init__(self):
        self.cache = {}  # ç¿»è¯‘ç¼“å­˜
        
    def translate_to_chinese(self, text):
        """ç®€å•çš„è‹±è¯‘ä¸­ï¼ˆè¿™é‡Œä½¿ç”¨åŸºç¡€è¯æ±‡æ›¿æ¢ï¼Œå®é™…åº”ç”¨ä¸­å»ºè®®ä½¿ç”¨ä¸“ä¸šç¿»è¯‘APIï¼‰"""
        if not text or text in self.cache:
            return self.cache.get(text, text)
            
        # åŸºç¡€è¯æ±‡æ›¿æ¢ï¼ˆå¯æ‰©å±•ï¼‰
        translations = {
            'free': 'å…è´¹',
            'deal': 'ä¼˜æƒ ',
            'offer': 'ä¼˜æƒ ',
            'discount': 'æŠ˜æ‰£',
            'save': 'çœé’±',
            'sale': 'ä¿ƒé”€',
            'voucher': 'ä¼˜æƒ åˆ¸',
            'code': 'ä»£ç ',
            'cashback': 'è¿”ç°',
            'student': 'å­¦ç”Ÿ',
            'new': 'æ–°',
            'exclusive': 'ç‹¬å®¶',
            'limited': 'é™æ—¶',
            'today': 'ä»Šå¤©',
            'now': 'ç°åœ¨',
            'get': 'è·å¾—',
            'buy': 'è´­ä¹°',
            'shop': 'è´­ç‰©',
            'online': 'åœ¨çº¿',
            'delivery': 'é…é€',
            'shipping': 'è¿è´¹'
        }
        
        translated = text.lower()
        for en, zh in translations.items():
            translated = translated.replace(en, zh)
            
        # ä¿æŒåŸæ–‡çš„å¤§å°å†™ç»“æ„
        result = self._preserve_case_structure(text, translated)
        self.cache[text] = result
        return result
        
    def _preserve_case_structure(self, original, translated):
        """ä¿æŒåŸæ–‡çš„å¤§å°å†™ç»“æ„"""
        if not original:
            return translated
        if original.isupper():
            return translated.upper()
        if original.istitle():
            return translated.title()
        return translated

class DealParser(HTMLParser):
    """HTMLè§£æå™¨"""
    
    def __init__(self):
        super().__init__()
        self.deals = []
        self.current_deal = {}
        self.in_deal_container = False
        self.in_title = False
        self.in_description = False
        self.current_tag = None
        
    def handle_starttag(self, tag, attrs):
        self.current_tag = tag
        attrs_dict = dict(attrs)
        
        # æ£€æµ‹å¯èƒ½çš„ä¼˜æƒ å®¹å™¨
        if tag in ['article', 'div'] and any('deal' in str(v).lower() or 'post' in str(v).lower() 
                                           for v in attrs_dict.values()):
            self.in_deal_container = True
            self.current_deal = {}
            
        # æ£€æµ‹æ ‡é¢˜
        if tag in ['h1', 'h2', 'h3', 'h4'] and self.in_deal_container:
            self.in_title = True
            
        # æ£€æµ‹æè¿°
        if tag == 'p' and self.in_deal_container:
            self.in_description = True
            
        # æ£€æµ‹é“¾æ¥
        if tag == 'a' and self.in_deal_container and 'href' in attrs_dict:
            if 'url' not in self.current_deal:
                self.current_deal['url'] = attrs_dict['href']
                
        # æ£€æµ‹å›¾ç‰‡
        if tag == 'img' and self.in_deal_container:
            if 'src' in attrs_dict:
                self.current_deal['image'] = attrs_dict['src']
            elif 'data-src' in attrs_dict:
                self.current_deal['image'] = attrs_dict['data-src']
                
    def handle_endtag(self, tag):
        if tag in ['article', 'div'] and self.in_deal_container:
            if self.current_deal and 'title' in self.current_deal:
                self.deals.append(self.current_deal.copy())
            self.in_deal_container = False
            self.current_deal = {}
            
        if tag in ['h1', 'h2', 'h3', 'h4']:
            self.in_title = False
            
        if tag == 'p':
            self.in_description = False
            
    def handle_data(self, data):
        data = data.strip()
        if not data:
            return
            
        if self.in_title and self.in_deal_container:
            self.current_deal['title'] = data
            
        if self.in_description and self.in_deal_container:
            if 'description' not in self.current_deal:
                self.current_deal['description'] = data
            else:
                self.current_deal['description'] += ' ' + data

class SimpleFreeStuffCrawler:
    """ç®€åŒ–ç‰ˆä¼˜æƒ çˆ¬è™«"""
    
    def __init__(self):
        self.base_url = "https://www.latestfreestuff.co.uk"
        self.translator = SimpleTranslator()
        self.session = requests.Session()
        self.setup_logging()
        
        # è®¾ç½®è¯·æ±‚å¤´
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.5',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
        }
        self.session.headers.update(self.headers)
        
    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('simple_crawler.log', encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)

    def get_page_content(self, url):
        """è·å–é¡µé¢å†…å®¹"""
        try:
            self.logger.info(f"æ­£åœ¨è·å–é¡µé¢: {url}")
            response = self.session.get(url, timeout=30)
            response.raise_for_status()
            return response.text
        except Exception as e:
            self.logger.error(f"è·å–é¡µé¢å¤±è´¥ {url}: {e}")
            return None

    def parse_deals(self, html_content):
        """è§£æä¼˜æƒ ä¿¡æ¯"""
        if not html_content:
            return []
            
        parser = DealParser()
        parser.feed(html_content)
        
        # æ¸…ç†å’ŒéªŒè¯æ•°æ®
        valid_deals = []
        for deal in parser.deals[:10]:  # é™åˆ¶æœ€å¤š10ä¸ª
            if self.is_valid_deal(deal):
                deal = self.clean_deal_data(deal)
                valid_deals.append(deal)
                
        return valid_deals

    def is_valid_deal(self, deal):
        """éªŒè¯ä¼˜æƒ ä¿¡æ¯"""
        if not deal.get('title'):
            return False
        if len(deal['title']) < 5:
            return False
        return True

    def clean_deal_data(self, deal):
        """æ¸…ç†ä¼˜æƒ æ•°æ®"""
        # æ¸…ç†æ ‡é¢˜
        if 'title' in deal:
            deal['title'] = re.sub(r'\\s+', ' ', deal['title']).strip()
            
        # æ¸…ç†æè¿°
        if 'description' in deal:
            deal['description'] = re.sub(r'\\s+', ' ', deal['description']).strip()
            deal['description'] = deal['description'][:300]  # é™åˆ¶é•¿åº¦
            
        # ä¿®å¤URL
        if 'url' in deal and not deal['url'].startswith('http'):
            if deal['url'].startswith('/'):
                deal['url'] = self.base_url + deal['url']
            else:
                deal['url'] = self.base_url + '/' + deal['url']
                
        # ä¿®å¤å›¾ç‰‡URL
        if 'image' in deal and not deal['image'].startswith('http'):
            if deal['image'].startswith('/'):
                deal['image'] = self.base_url + deal['image']
            else:
                deal['image'] = self.base_url + '/' + deal['image']
                
        # æ·»åŠ æ—¥æœŸ
        deal['date'] = datetime.now().strftime('%Y-%m-%d')
        
        return deal

    def translate_deals(self, deals):
        """ç¿»è¯‘ä¼˜æƒ ä¿¡æ¯"""
        translated_deals = []
        
        for i, deal in enumerate(deals):
            self.logger.info(f"ç¿»è¯‘ç¬¬ {i+1}/{len(deals)} ä¸ªä¼˜æƒ ...")
            
            translated_deal = deal.copy()
            
            # ç¿»è¯‘æ ‡é¢˜
            if 'title' in deal:
                translated_deal['title_zh'] = self.translator.translate_to_chinese(deal['title'])
                
            # ç¿»è¯‘æè¿°
            if 'description' in deal:
                translated_deal['description_zh'] = self.translator.translate_to_chinese(deal['description'])
                
            translated_deals.append(translated_deal)
            time.sleep(0.5)  # é¿å…è¿‡äºé¢‘ç¹
            
        return translated_deals

    def save_deals(self, deals):
        """ä¿å­˜ä¼˜æƒ ä¿¡æ¯"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # ä¿å­˜JSON
        os.makedirs('data', exist_ok=True)
        json_file = f"data/deals_{timestamp}.json"
        
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(deals, f, ensure_ascii=False, indent=2)
            
        self.logger.info(f"å·²ä¿å­˜ {len(deals)} ä¸ªä¼˜æƒ åˆ° {json_file}")
        
        # ç”ŸæˆHTML
        html_content = self.generate_html(deals)
        html_file = f"data/deals_{timestamp}.html"
        
        with open(html_file, 'w', encoding='utf-8') as f:
            f.write(html_content)
            
        return json_file, html_file

    def generate_html(self, deals):
        """ç”ŸæˆHTMLå†…å®¹"""
        html = """
        <div class="daily-deals-section">
            <h2>ğŸ ä»Šæ—¥è‹±å›½ä¼˜æƒ ç²¾é€‰</h2>
            <p class="update-time">æ›´æ–°æ—¶é—´: {}</p>
            <div class="deals-container">
        """.format(datetime.now().strftime('%Y-%m-%d %H:%M:%S'))
        
        for deal in deals:
            title_zh = deal.get('title_zh', deal.get('title', ''))
            desc_zh = deal.get('description_zh', deal.get('description', ''))[:100] + "..."
            
            html += f"""
            <div class="deal-item">
                <h3>{title_zh}</h3>
                <p>{desc_zh}</p>
                <div class="deal-meta">
                    <span class="date">ğŸ“… {deal.get('date', '')}</span>
                    <a href="{deal.get('url', '#')}" target="_blank" class="deal-link">æŸ¥çœ‹è¯¦æƒ…</a>
                </div>
            </div>
            """
            
        html += """
            </div>
        </div>
        """
        
        return html

    def run_crawler(self):
        """è¿è¡Œçˆ¬è™«"""
        self.logger.info("å¼€å§‹çˆ¬å–ä¼˜æƒ ä¿¡æ¯...")
        
        # è·å–é¡µé¢
        html_content = self.get_page_content(self.base_url)
        if not html_content:
            self.logger.error("æ— æ³•è·å–ç½‘ç«™å†…å®¹")
            return []
            
        # è§£æä¼˜æƒ 
        deals = self.parse_deals(html_content)
        self.logger.info(f"æ‰¾åˆ° {len(deals)} ä¸ªä¼˜æƒ ")
        
        if not deals:
            return []
            
        # ç¿»è¯‘
        translated_deals = self.translate_deals(deals)
        
        # ä¿å­˜
        json_file, html_file = self.save_deals(translated_deals)
        
        self.logger.info(f"çˆ¬è™«å®Œæˆï¼æ–‡ä»¶: {json_file}, {html_file}")
        return translated_deals

def main():
    """ä¸»å‡½æ•°"""
    crawler = SimpleFreeStuffCrawler()
    deals = crawler.run_crawler()
    
    if deals:
        print(f"\\nâœ… æˆåŠŸçˆ¬å– {len(deals)} ä¸ªä¼˜æƒ ä¿¡æ¯:")
        for i, deal in enumerate(deals, 1):
            print(f"{i}. {deal.get('title_zh', deal.get('title', ''))}")
    else:
        print("âŒ æœªè·å–åˆ°ä¼˜æƒ ä¿¡æ¯")

if __name__ == "__main__":
    main()
